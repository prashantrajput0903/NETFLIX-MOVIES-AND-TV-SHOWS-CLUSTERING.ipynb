{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "PH-0ReGfmX4f",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "JcMwzZxoAimU",
        "8G2x9gOozGDZ",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prashantrajput0903/NETFLIX-MOVIES-AND-TV-SHOWS-CLUSTERING.ipynb/blob/main/Sample_EDA_Submission_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - \n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member  -**  Prashant Kumar\n"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flexible which is a third-party Netflix search engine.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/prashantrajput0903/NETFLIX-MOVIES-AND-TV-SHOWS-CLUSTERING.ipynb"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset consists of tv shows and movies available on Netflix as of 2019. The dataset is collected from Flixable which is a third-party Netflix search engine.\n",
        "\n",
        "In 2018, they released an interesting report which shows that the number of TV shows on Netflix has nearly tripled since 2010. The streaming service’s number of movies has decreased by more than 2,000 titles since 2010, while its number of TV shows has nearly tripled. It will be interesting to explore what all other insights can be obtained from the same dataset.\n",
        "\n",
        "Integrating this dataset with other external datasets such as IMDB ratings, rotten tomatoes can also provide many interesting findings."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Description\n",
        "show_id: Unique ID for every Movie / Tv Show\n",
        "\n",
        "type: Identifier - A Movie or TV Show\n",
        "\n",
        "title: Title of the Movie / Tv Show\n",
        "\n",
        "director: Director of the Movie\n",
        "\n",
        "cast: Actors involved in the movie/show\n",
        "\n",
        "country: The country where the movie/show was produced\n",
        "\n",
        "date_added: Date it was added on Netflix\n",
        "\n",
        "release_year: Actual Releaseyear of the movie/show\n",
        "\n",
        "rating: TV Rating of the movie/show\n",
        "\n",
        "duration: Total Duration - in minutes or number of seasons\n",
        "\n",
        "listed_in : Genre\n",
        "\n",
        "description: The Summary description"
      ],
      "metadata": {
        "id": "fBPVfaliVbXR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Define Your Business Objective?**"
      ],
      "metadata": {
        "id": "PH-0ReGfmX4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I used some the tools such as Text processing, and K-Means Clustering algorithms to get insights from the dataset. And also used some validation techniques to check the accuracy of the model for example Silhouette Score, and Elbow Method."
      ],
      "metadata": {
        "id": "PhDvGCAqmjP1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#In this project, you are required to do\n",
        "Exploratory Data Analysis\n",
        "\n",
        "Understanding what type content is available in different countries\n",
        "\n",
        "Is Netflix has increasingly focusing on TV rather than movies in recent years.\n",
        "\n",
        "Clustering similar content by matching text-based features"
      ],
      "metadata": {
        "id": "VNCGmC4kVtE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Attribute Information"
      ],
      "metadata": {
        "id": "byFroLVBV18S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. show_id : Unique ID for every Movie / Tv Show\n",
        "\n",
        "2. type : Identifier - A Movie or TV Show\n",
        "\n",
        "3. title : Title of the Movie / Tv Show\n",
        "\n",
        "4. director : Director of the Movie\n",
        "\n",
        "5. cast : Actors involved in the movie / show\n",
        "\n",
        "6. country : Country where the movie / show was produced\n",
        "\n",
        "7. date_added : Date it was added on Netflix\n",
        "\n",
        "8. release_year : Actual Releaseyear of the movie / show\n",
        "\n",
        "9. rating : TV Rating of the movie / show\n",
        "\n",
        "10. duration : Total Duration - in minutes or number of seasons\n",
        "\n",
        "11. listed_in : Genere\n",
        "\n",
        "12. description: The Summary description"
      ],
      "metadata": {
        "id": "75Opvp29V4m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the required libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score"
      ],
      "metadata": {
        "id": "oyw56n5XVnDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "aLAVUi2EWDFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/NETFLIX MOVIES AND TV SHOWS CLUSTERING.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "njM6tbvMWK7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "-QscEimTWN0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "YsjQXO14WSIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the unique val for each col\n",
        "df.nunique()"
      ],
      "metadata": {
        "id": "aSn-eB1wWUa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By Checking with unique values we saw that there are lots of error which we can send our data for further cleaning."
      ],
      "metadata": {
        "id": "euEGB22hWbCQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DATA CLEANING"
      ],
      "metadata": {
        "id": "EhneOd6pWefs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In here our task is to remove the **Duplicates values, Null And Missing values**."
      ],
      "metadata": {
        "id": "rvhYmQS9Wjv7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "f45ngCweWXL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop null values of \"date_added\" column\n",
        "df=df.dropna(subset=['date_added'])\n",
        "\n",
        "#Replacing null values with \"NULL\" in rest four columns\n",
        "df.fillna(\"NULL\",inplace=True)"
      ],
      "metadata": {
        "id": "jh5Lr1vxWnPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_duplicate = df.duplicated(keep = False).any()\n",
        "if check_duplicate == False:\n",
        "    print('There are no duplicate rows in our dataset')\n",
        "else:\n",
        "    print ('There is an duplicates rows in our dataset')"
      ],
      "metadata": {
        "id": "2AyTX13cWqJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,5))\n",
        "c=sns.countplot(x=df.type, palette=\"pastel\")\n",
        "plt.title(\"Count of movies and show\")\n",
        "plt.xlabel(\"Movies/Shows\")\n",
        "plt.ylabel(\"Total Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j-h9yBUWbWeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(13,7))\n",
        "plt.title(\"% of Netflix Titles that are either Movies or Shows\")\n",
        "g = plt.pie(df.type.value_counts(), labels=df.type.value_counts().index, colors=['pink','blue'],autopct='%1.1f%%', startangle=180);\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "65c-YZQiWsgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#order =  ['G', 'TV-Y', 'TV-G', 'PG', 'TV-Y7', 'TV-Y7-FV', 'TV-PG', 'PG-13', 'TV-14', 'R', 'NC-17', 'TV-MA']\n",
        "plt.figure(figsize=(15,7))\n",
        "g = sns.countplot(x=df.rating, hue=df.type, palette=\"pastel\");\n",
        "plt.title(\"Ratings for Movies & TV Shows\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Total Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "miY54PiDWupH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "order =  ['G', 'TV-Y', 'TV-G', 'PG', 'TV-Y7', 'TV-Y7-FV', 'TV-PG', 'PG-13', 'TV-14', 'R', 'NC-17', 'TV-MA']\n",
        "plt.figure(figsize=(15,7))\n",
        "g = sns.countplot(x=df.rating, hue=df.type, order=order, palette=\"pastel\");\n",
        "plt.title(\"Ratings for Movies & TV Shows\")\n",
        "plt.xlabel(\"Rating\")\n",
        "plt.ylabel(\"Total Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TpeZ4cY8Wxln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1,2, figsize=(19, 5))\n",
        "g1 = sns.countplot(x=df.rating, order=order,palette=\"Set2\", ax=ax[0]);\n",
        "g1.set_title(\"Ratings for Movies\")\n",
        "g1.set_xlabel(\"Rating\")\n",
        "g1.set_ylabel(\"Total Count\")\n",
        "g2 = sns.countplot(x=df.rating, order=order,palette=\"Set2\", ax=ax[1]);\n",
        "g2.set(yticks=np.arange(0,1600,200))\n",
        "g2.set_title(\"Ratings for TV Shows\")\n",
        "g2.set_xlabel(\"Rating\")\n",
        "g2.set_ylabel(\"Total Count\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "OKmL2StvWzyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Yearly produced content"
      ],
      "metadata": {
        "id": "_nZ_FknvcFUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of years when content was added\n",
        "years = list(range(2008,2020,1))\n",
        "# Seperate Rows having only movies as content\n",
        "movie_rows=df.loc[df[\"type\"] == \"Movie\"]\n",
        "# Seperate Rows having only TV Shows as content\n",
        "tv_rows=df.loc[df[\"type\"]==\"TV Show\"]\n",
        "\n",
        "movies_counts = movie_rows.release_year.value_counts()\n",
        "tv_counts = tv_rows.release_year.value_counts()\n",
        "\n",
        "index_years_mov = movies_counts.index.isin(years)\n",
        "index_years_tv = tv_counts.index.isin(years)\n",
        "\n",
        "#select movies / tv shows between chosen years:\n",
        "movies = movies_counts[index_years_mov]\n",
        "tv_shows = tv_counts[index_years_tv]"
      ],
      "metadata": {
        "id": "HYISj5bJboyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a line plot\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "sns.lineplot(data=movies, color=\"#8B0000\",  label=\"Movies / year\",marker='o')\n",
        "sns.lineplot(data=tv_shows, color=\"#FFC1C1\",  label=\"TV Shows / year\",marker='o')\n",
        "\n",
        "# remove the frame of the chart\n",
        "for spine in plt.gca().spines.values():\n",
        "    spine.set_visible(False)\n",
        "\n",
        "# Draw grid lines with red color and dashed style\n",
        "plt.grid(color='#E8E8E8', linestyle='--', linewidth=0.7)\n",
        "\n",
        "plt.legend(bbox_to_anchor=(1.02, 1), loc='upper left',\n",
        "             borderaxespad=0,frameon=False)\n",
        "\n",
        "\n",
        "plt.xlabel(\"Year Added\")\n",
        "plt.ylabel(\"Numbers\")\n",
        "plt.title('Movies/TV Shows Added per Year')"
      ],
      "metadata": {
        "id": "6ldcmxembwGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ":As we can see in this plot that TV shows and Movies content increased after 2016."
      ],
      "metadata": {
        "id": "g5wCHoC8cIXB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking the Ratings given by the users**."
      ],
      "metadata": {
        "id": "bGccY5qDcN32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "movie_ratings = df.groupby(['rating'])['show_id'].count().reset_index(name='count').sort_values(by='count',ascending=True)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "ax=sns.lineplot( x='rating',y='count',data=movie_ratings,color=\"#8B0000\",marker='o')\n",
        "\n",
        "# Annotate every single Bar with its value, based on it's width           \n",
        "for p in ax.patches:\n",
        "    width = p.get_width()\n",
        "    plt.text(65+p.get_x()+p.get_width(),p.get_y()+0.55*p.get_height(),\n",
        "             '{:1.0f}'.format(width),\n",
        "             ha='center', va='center')\n",
        "\n",
        "# Removing all ticks and label\n",
        "plt.tick_params(top=False, bottom=False, left=False, right=False, \n",
        "                labelleft=True, labelbottom=True)\n",
        "\n",
        "\n",
        "# remove the frame of the chart\n",
        "for spine in plt.gca().spines.values():\n",
        "    spine.set_visible(False)\n",
        "# Draw grid lines with red color and dashed style\n",
        "plt.grid(color='#E8E8E8', linestyle='--', linewidth=0.7)\n",
        "\n",
        "ax.set(xlabel=\"Ratings\", ylabel = \"Count\")\n",
        "plt.title('Top content Ratings')\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vo4IGv9Gb-OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Text Processing**\n",
        "\n",
        "The text processing is used to remove the punctuations and stopwords etc."
      ],
      "metadata": {
        "id": "m2xi85JZcU6R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "REMOVING THE PUNCTUATIONS."
      ],
      "metadata": {
        "id": "PMdGnGMOcZPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "def remove_punctuation(text):\n",
        "    '''a function for removing punctuation'''\n",
        "\n",
        "    import string\n",
        "    \n",
        "    # replacing the punctuations with no space, \n",
        "    # which in effect deletes the punctuation marks \n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # return the text stripped of punctuation marks\n",
        "    return text.translate(translator)\n",
        "# Applying the function to remove punctuations\n",
        "df['description'] = df['description'].apply(remove_punctuation)\n",
        "\n",
        "# Applying the function to remove punctuations\n",
        "df['listed_in'] = df['listed_in'].apply(remove_punctuation)"
      ],
      "metadata": {
        "id": "G0ZPzu9vcRNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REMOVING STOPWORDS"
      ],
      "metadata": {
        "id": "rY1QxY5Qch_g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing natural language tool kit\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n"
      ],
      "metadata": {
        "id": "g7YPeySocZz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sw = stopwords.words('english')\n",
        "\n",
        "# Function to remove stopwords \n",
        "def stopwords(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)\n",
        "# Applying the stopword function\n",
        "df['description'] = df['description'].apply(stopwords)\n",
        "\n",
        "# Applying the stopword function\n",
        "df['listed_in'] = df['listed_in'].apply(stopwords)"
      ],
      "metadata": {
        "id": "Tyj1RD3YckjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEMMING OF WORDS"
      ],
      "metadata": {
        "id": "BDUvjBCMcpl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def stemming(text):    \n",
        "    '''a function which stems each word in the given text'''\n",
        "    text = [stemmer.stem(word) for word in text.split()]\n",
        "    return \" \".join(text)  \n",
        "#stemming for description\n",
        "df['description'] = df['description'].apply(stemming)"
      ],
      "metadata": {
        "id": "pdcfrst4cnHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have to rescale our data to sent further for the prediction by using unsupervised learning technique."
      ],
      "metadata": {
        "id": "wWms6rRWcx91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to display text length\n",
        "def length(text):    \n",
        "    '''a function which returns the length of text'''\n",
        "    return len(text)\n",
        "# Create two variables for description and listed-in texts length respectively\n",
        "df['desc_length'] = df['description'].apply(length)\n",
        "df['listed_length'] = df['listed_in'].apply(length)\n",
        "# Create a dataframe with variables indicating text lengths only\n",
        "cluster_df=df.filter(['desc_length','listed_length'],axis=1)\n",
        "cluster_df.head(2)"
      ],
      "metadata": {
        "id": "AxgXf6VWcrqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_features_rec_mon=df[['desc_length','listed_length']]\n",
        "scaler_rec_mon=preprocessing.StandardScaler()\n",
        "X_rec_mon=scaler_rec_mon.fit_transform(X_features_rec_mon)\n",
        "X=X_rec_mon"
      ],
      "metadata": {
        "id": "vU-IISwlcudD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementing K-MEANS Algorithm"
      ],
      "metadata": {
        "id": "67LPLKcPc4kC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_1 = []\n",
        "\n",
        "# for loop to append kmeans inertia values\n",
        "for k in range(1,10):\n",
        "    kmeans = KMeans(n_clusters=k)\n",
        "    kmeans.fit(X)\n",
        "    list_1.append(kmeans.inertia_)\n",
        "\n",
        "#Plot linegraph\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "plt.plot(range(1,10),list_1,\"-o\")\n",
        "plt.grid(True)\n",
        "plt.xlabel(\"Number of Clusters(k)\",fontsize=12)\n",
        "plt.ylabel(\"Sum of Square Distances\",fontsize=12)\n",
        "plt.title(\"Elbow Method For Optimal k\",fontsize=14)\n",
        "plt.xticks(range(1,10))\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "2zgExThSc2gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In here we are finding the optimum number of clusters by using ELBOW METHOD**\n",
        "\n",
        "The elbow method runs k-means clustering on the dataset for a range of k values ex(1 to 10).\n",
        "\n",
        "And in this we have to performing k-means clustering with all the k values.\n"
      ],
      "metadata": {
        "id": "B5x6fP6MdCZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Silhouette Score**\n",
        "\n",
        "Now we have to use silhouette score which gives the accuracy of our model."
      ],
      "metadata": {
        "id": "DZp035sYdHXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate silhoutte score for K-means\n",
        "range_n_clusters = [2,3,4,5,6,7,8]\n",
        "for n_clusters in range_n_clusters:\n",
        "    clusterer = KMeans(n_clusters=n_clusters)\n",
        "    preds = clusterer.fit_predict(X)\n",
        "    centers = clusterer.cluster_centers_\n",
        "\n",
        "    score = silhouette_score(X, preds)\n",
        "    print(\" n_clusters = {}, silhouette score is {}\".format(n_clusters, score))"
      ],
      "metadata": {
        "id": "tUThzIqac9iL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see here that by using silhoutte score the more accuracy our n_cluster = 7 is giving"
      ],
      "metadata": {
        "id": "mR3xFsEndVFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "In this notebook we having Netflix datset which we have to predict by using Unsupervised Learning. In this dataset first i had done the Cleaning & EDA which is very important for the further process and then i had done Text processing and rescled data for prediction, and at last i used k-means clustering algorithm and checked for accuracy by using silhouette score."
      ],
      "metadata": {
        "id": "G-HA3GTPdXv6"
      }
    }
  ]
}
